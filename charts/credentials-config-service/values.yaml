## Default values for til.
## This is a YAML-formatted file.
## Declare variables to be passed into your templates.

# -- option to override the name config in the _helpers.tpl
nameOverride: ""
# -- option to override the fullname config in the _helpers.tpl
fullnameOverride: ""

## configuration for the k8s service to access til
service:
  # -- service type
  type: ClusterIP
  # -- port to be used by the service
  port: 8080
  # -- additional annotations, if required
  annotations: {}

# -- if a til specific service account should be used, it can be configured here
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
serviceAccount:
  # -- specifies if the account should be created
  create: false

## deployment specific configuration
deployment:
  # -- initial number of target replications, can be different if autoscaling is enabled
  replicaCount: 1
  # -- number of old replicas to be retained
  revisionHistoryLimit: 3
  ## configuration of the til update strategy
  updateStrategy:
    # -- type of the update
    type: RollingUpdate
    # -- new pods will be added gradually
    rollingUpdate:
      # -- number of pods that can be created above the desired amount while updating
      maxSurge: 1
      # -- number of pods that can be unavailable while updating
      maxUnavailable: 0
  ## configuration of the image to be used
  image:
    # -- til image name
    # ref: https://quay.io/repository/fiware/credentials-config-service
    repository: quay.io/fiware/credentials-config-service
    # -- tag of the image to be used
    tag: 1.1.0
    # -- specification of the image pull policy
    pullPolicy: IfNotPresent
  # -- additional labels for the deployment, if required
  additionalLabels: {}
  # -- additional annotations for the deployment, if required
  additionalAnnotations: {}
  ## til resource requests and limits, we leave the default empty to make that a concious choice by the user.
  ## for the autoscaling to make sense, you should configure this.
  # resources:
    # limits:
      # cpu: 100m
      # memory: 128Mi
    # requests:
      # cpu: 100m
      # memory: 128Mi
  # -- selector template
  # ref: https://kubernetes.io/docs/user-guide/node-selection/
  nodeSelector: {}
  # -- tolerations template
  # ref: ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []
  # -- affinity template
  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}
  # -- port to request health information at
  healthPort: 9090
  ## liveness and readiness probes
  # ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 30
  readinessProbe:
    initialDelaySeconds: 31
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 30

## pod autoscaling configuration, use for automatic scaling of the broker pods
autoscaling:
  #  -- should autoscaling be enabled for til
  enabled: false
  # -- minimum number of running pods
  minReplicas: 1
  # -- maximum number of running pods
  maxReplicas: 10
  # -- metrics to react on
  metrics: []
  ## List of MetricSpecs to decide whether to scale
  # See https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#metricspec-v2beta2-autoscaling
  # scaler targets to hold average cpu around 80%
  #- type: Resource
  #  resource:
  #    name: cpu
  #     target:
  #      type: Utilization
  #      averageUtilization: 80
  ## scaler targets to hold average memory around 80%
  #  - type: Resource
  #    resource:
  #      name: memory
  #      target:
  #        type: Utilization
  #        averageUtilization: 80

## openshift specific route definition. Will not work on plain k8s
route:
  ## -- should the deployment create openshift routes
  enabled: false
  # -- annotations to be added to the route
  annotations: {}
  # -- host to be used
  # host: localhost
  # -- tls configuration for the route
  tls: {}
  # termination: edge
  # configuration for creation of certificates, using cert-manager.
  certificate: {}
  # allows to specify the issuer to be used.
  # issuer:
  #   kind: ClusterIssuer
#   name: letsencrypt-aws-prod

## ingress configuration
ingress:
  # -- should there be an ingress to connect til with the public internet
  enabled: false
  # -- annotations to be added to the ingress
  annotations: {}
    # kubernetes.io/ingress.class: "ambassador"
    ## example annotations, allowing cert-manager to automatically create tls-certs and forcing everything to use ssl.
    # kubernetes.io/tls-acme: "true"
    # ingress.kubernetes.io/ssl-redirect: "true"
  # -- all hosts to be provided
  hosts: []
    ## provide a hosts and the paths that should be available
    # - host: localhost
      # paths:
      # - /
  # -- configure the ingress' tls
  tls: []
    # - secretName: til-tls
      # hosts:
        # - til.fiware.org

# -- port that the til container uses
port: 8080

## configuration for prometheus montioring
prometheus:
  # -- should prometheus scrape be enabled
  enabled: true
  # -- path for prometheus scrape
  path: /prometheus
  # -- port prometheus scrape is available at
  port: 9090

# -- a list of additional env vars to be set, check the til docu for all available options
additonalEnvVars: []

## database configuration for the credentials-config-service
database:
  # -- should the database support persistence? If disabled, a H2-InMemory-Database will be used. 
  persistence: false
  # -- host of the database to be connected - will be ignored if persistence is disabled
  host: mysql
  # -- port of the database to be connected - will be ignored if persistence is disabled
  port: 3306
  # -- name of the database-schema to be accessed - will be ignored if persistence is disabled
  name: ccs-db 
  # -- username to conncet the db - ignored if existing secret is configured
  username: user
  # -- passowrd to connect the db - ignored if existing secret is configured
  password: password
  # -- existing secret to retrieve the db password
  existingSecret:
    # -- should an existing secret be used
    enabled: false
    # -- name of the secret
    name: the-secret
    # -- key to retrieve the password from
    key: password



